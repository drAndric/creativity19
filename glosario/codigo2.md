PROYECTO GLOSARIO DE FILOSOFÍA DE LA TÉCNICA
============================================

Entrada: Código
---------------

En contextos tecnológicos, código se refiere generalmente a al menos a
dos conceptos distintos, aunque profundamente relacionados. Por un lado,
hay que entender código en sentido estricto, según el cual un código no
es otra cosa que un conjunto de reglas que se usa para convertir un
patrón en otro patrón, cuyas propiedades nuevas lo hacen más susceptible
de ser, por ejemplo, transmitido por un medio que tiene otras
características físicas que el original (ver **patrón**). Esto es, un
patrón significativo para un agente se *codifica* por medio de un código
--la serie de reglas para su conversión-- para ser almacenado en un
medio que lo puede preservar por más tiempo --e.g. la escritura--, para
transmitirlo por un telégrafo --e.g. el código Morse--, para generar
estándares -- e.g. el código de IATA para designar aeropuertos, el
código ASCII para representar caracteres--, por razones de seguridad --
el código de la máquina Enigma o algo más sencillo como una escítala--,
etc. La utilidad de un código está sujeta a la capacidad de un agente de
*decodificarlo*, esto es, recuperar al menos algunas de las propiedades
significativas del patrón original, ya sea consciente o
inconscientemente, por medios tecnológicos o cognitivos, externos o no.
Así, el código se puede ver como un recurso para convertir un medio
físico en un canal de comunicación, sin generar cambios estructurales en
el medio sino tan solo implementando computaciones en ambos extremos del
canal de comunicación (ver **información**, **computación**). La
necesidad de crear *buenos* códigos está motivada por la necesidad de
mantener una misma representación con menos recursos (de tiempo y/o
espacio para *comprimir* la descripción) y de poder utilizar medios que
pueden introducir distorsiones en las señales, que no deberían afectar
la capacidad de reconstruir el patrón original (ver
**referenciabilidad**). Esto llevó a la aparición del campo de
investigación denominado "teoría de códigos" que puede considerase como
una aplicación directa de la teoría de la información, y en donde
confluyen diversas áreas de la matemática como el álgebra abstracta, la
probabilidad y la geometría.

Por otro lado, el sentido amplio en el que hay que entender "código" es
como referencia a la versión "estática" o "textual" de un programa o
software, es decir, el conjunto de instrucciones escrito (léase
*codificado*) en algún lenguaje de programación que da lugar a la
versión "procesual" del programa o software que efectivamente se puede
ejecutar en una arquitectura computacional (ver **programa**). Es
específicamente esta *potencialidad* de ser programa lo que hace que
esta forma de ver a un código necesite una lectura filosófica
específica. Esto le otorga una capacidad *agencial* a esta clase de
códigos, siendo un caso límite el del código que puede ser su propio
agente de interpretación. Lo que hace de esta forma de entender al
código un sentido *amplio*, y diferenciarse del sentido estricto,
consiste en la "indeterminación" del código original luego de ser
*traducido* a un programa. Esto es, cuando el aspecto performativo y
agencial del código se pone de manifiesto, es imposible recuperar el
código original desde el programa o software. Por esta razón, una forma
usual de referirse a "código" en este sentido es hablar del "código
fuente" de un programa. El término "*open source*" o "fuente abierta"
hace referencia precisamente al hecho de que el código del programa está
disponible para quien desee inspeccionarlo, ya sea para aprender de él,
para evaluar su aplicabilidad y corrección a ciertos usos, o para
tomarlo como recurso para otro proyecto. Es importante notar que cuando
se se usan programas o plataformas cuyo código no está disponible para
la inspección de los usuarios, se está frente a un caso de opacidad
epistémica, en tanto los procesos computacionales que están detrás de
las operaciones de los usuarios pueden ser desconocidos. La opacidad es
tanto mayor si, como ocurre en prácticamente todos los casos cuando se
usa software privativo con "código cerrado", detrás de las
implementaciones existen un sinnúmero de decisiones no documentadas ni
comunicadas que pueden tener un impacto directo y negativo en la vida de
muchos usuarios, especialmente cuando son a gran escala y hacen uso de
algoritmos de aprendizaje automatizado (ver **inteligencia
artificial**).

La potencialidad de ser programa está dada porque el agente al que está
destinado el código es una computadora, esto es, un dispositivo que
puede interpretar los elementos del código como una serie de operaciones
mecánicas que puede realizar. Así, el objetivo del código es controlar o
gobernar el comportamiento de un dispositivo -existente o posible- con
el objetivo de lograr un resultado. La secuencia pasos que se *diseña*
mediante el código constituyen un algoritmo, que gracias a la
manipulación de valores -efectivamente patrones que hacen a la memoria
de la computadora- se logra obtener otro estado de la máquina que quien
diseñó la secuencia considera relevante o necesario obtener (ver
**programa**, **algoritmo**). Aquí surgen una serie anidada de problemas
filosóficos, que van desde la naturaleza de la computación hasta las
capacidades de los lenguajes, tanto naturales como artificiales. El
término "código", de hecho, se usó en el sentido de "lenguaje de
programación" para referirse a una manera simplificada de escribir las
instrucciones de una computadora, de manera tal que pudieran ser
escritas y leídas con más facilidad por las personas avocadas a tal
tarea. Así, el "código corto" \[*short* o *brief code*\] introducido por
John Mauchly (diseñador de la ENIAC, junto con J. Presper Eckert) fue
uno de los primeros "lenguajes de programación de alto nivel", que logró
ser implementado, aunque no el primero en ser diseñado. El primero
probablemente haya sido "cálculo de planes" \[*Plankalkül*\] que Konrad
Zuse comenzó a diseñar hacia 1939 con la idea de lograr un equivalente a
un sistema deductivo con el cual se pudieran expresar algoritmos. Los
lenguajes de "alto nivel" se contrastan con los de "bajo nivel", cuya
representación es mucho más cercana a los valores binarios con los que
trabaja la arquitectura computacional particular, que estrictamente solo
"entiende" el llamado "lenguaje o código de máquina". El primer lenguaje
que intentó dejar de lado incluso la representación matemática fue el
FLOW-MATIC, diseñado por Grace Hopper para ser mucho más similar al
inglés. Este lenguaje tuvo gran influencia en el diseño de COBOL,
todavía utilizado hasta la actualidad. De la misma manera en que un
lenguaje natural subsiste si hay personas que lo hablen, un código puede
considerarse exitoso en tanto logre generar una comunidad de usuarios
que lo encuentre útil para ciertos propósitos.

Curiosamente, hay otro sentido directamente vinculado por medio del cual
un código puede *hacer* a una comunidad, y la conexión está en la
normatividad que un código puede expresar. Así, una persona puede
considerarse miembro de una comunidad si es que respeta una serie de
normas preestablecidas por sus otros miembros, que normalmente se
expresan en un *código*, como es el Código Civil, el *Codex Iustinuanus*
o incluso el *Codex Alimentarius*. Curiosamente, estos códigos se suelen
recopilar en un *códice*, que es el formato que se suele asociar a un
libro. (Los dos términos derivan de la locución latina *caudex*, que si
bien refiere originalmente al tronco de un árbol es la manera en la que
los romanos le dieron a las tablillas de ceras usadas para escribir, que
solían tener un marco de madera). Así, de la misma manera en la que un
programa es el resultado de un código usado para representar una
secuencia deseada de estados de una máquina, de hecho, diseñado su
comportamiento, un código establece el comportamiento esperado ante
ciertas situaciones (i.e. estados) de individuos en una sociedad, por lo
que en principio tienen la capacidad efectiva de diseñar el
comportamiento de la sociedad como un todo. También de manera similar a
lo que sucede con las leyes y las normas, un lenguaje de programación
puede ser, por ejemplo, imperativo y definir directamente la forma en la
que un estado debe ser transformado en otro, aunque también puede ser
declarativo, y especificar el estado al que se debe llegar, pero sin
determinar por completo el flujo de control de la secuencia de
operaciones.

Uno de los problemas más discutidos concierne a la relación entre los
distintos elementos que estructuran al código y su función, y de hecho
se trata de uno de los puntos de intersección más interesantes entre las
filosofías del lenguaje, de la matemática, de la técnica y de la mente.
Estrictamente, tanto los lenguajes naturales como los artificiales o
formales pueden ser caracterizados como un conjunto de oraciones que se
forma a partir de un vocabulario básico. Partiendo de un alfabeto,
normalmente un conjunto finito de símbolos elegidos arbitrariamente, se
pueden conformar palabras mediante distintas concatenaciones de las
letras o símbolos del alfabeto, o incluso de otras palabras. La
*sintaxis* de un lenguaje surge de fijar su estructura léxica y
gramatical mediante un conjunto de reglas (la manera usual es fijarlas
mediante expresiones regulares y gramáticas libres de contexto,
respectivamente). La posición clásica sostiene que la sintaxis no
alcanza para determinar el *sentido* o el *significado* de las
expresiones, por lo que es necesario incorporar una dimensión semántica
que determine cuál es el sentido de una operación. Por ejemplo, la
expresión de la forma "x += y" tiene una sintaxis particular a un
lenguaje, mientras que otra expresión como "ADD Y TO X GIVING X" es
sintácticamente muy distinta, sin embargo, expresan el mismo sentido.
Estos problemas se pueden rastrear, al menos, hasta los trabajos de
Gotlob Frege sobre la naturaleza de la matemática y la lógica. Si bien
la semántica de un lenguaje formar se puede fijar de manera precisa,
existen muchas posibilidades para hacerlo, como las semánticas
operacionales, las denotacionales y las axiomáticas. Saul Kripke,
ayudado por una lectura particular de las obras de Wittgenstein, fue uno
de los primeros en sugerir que detrás de toda lectura del significado de
una expresión yacen condiciones que regulan la aceptabilidad o
adecuación de la expresión, por lo que fijar el significado requiere, en
realidad, dar cuenta de la normatividad que determina las condiciones de
corrección. Un problema con la lectura clásica es que suele dejar de
lado los aspectos procesuales latentes y concentrarse exclusivamente en
los aspectos estructurales del lenguaje y su uso. Aquí es donde la
filosofía de la tecnología puede hacer una contribución fundamental al
debate, en tanto los mismos elementos entran juego en el diseño de un
artefacto, especialmente si se trata de un artefacto cuyo propósito es
realizar cómputos. En esta dirección, se debería considerarla relación
entre la sintaxis y la semántica del código está dada, en realidad, por
la forma en la que una regla *implementa* otra regla. La implementación
de una regla (y de un conjunto de reglas, como un lenguaje de
programación) es el aspecto crucial que, en última instancia, determina
el verdadero sentido de las expresiones y permite llevarlas a cabo y
efectivamente desenvolver su potencialidad de ser programa, que es su
caracterización dinámica (ver. **computación**, **programa**).

**Bibliografía sugerida**

Berry, D. (2016). *The philosophy of software: Code and mediation in the
digital age*. Springer.

Dretske, F. (1981). *Knowledge and the flow of information*. MIT Press.

Fuller, M. (2008). *Software studies: A lexicon*. MIT Press.

Rapaport, W. J. (1995). Understanding understanding: Syntactic semantics
and computational cognition. *Philosophical Perspectives*, *9*, 49.
<https://doi.org/10.2307/2214212>

Shannon, C. E. (1949). Communication Theory of Secrecy Systems. *Bell
System Technical Journal*, *28*(4), 656-715.

### Ver también

algoritmo. computación. información. inteligencia aritificial. interfaz.
patrón. programa. referenciabilidad.
